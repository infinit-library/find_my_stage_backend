const EventbriteScraperService = require('../services/eventbrite-scraper.service');
const EventbriteApiService = require('../services/eventbrite-api.service');
const PaperCallScraperService = require('../services/papercall-scraper.service');
const PlaywrightPaginationScraperService = require('../services/playwright-pagination-scraper.service');
const PretalxScraperService = require('../services/pretalx-scraper.service');
const PretalxScraperSimpleService = require('../services/pretalx-scraper-simple.service');
const PretalxDirectService = require('../services/pretalx-direct.service');
const { PrismaClient } = require('@prisma/client');

const prisma = new PrismaClient();
const scraperService = new EventbriteScraperService();
const apiService = new EventbriteApiService(process.env.EVENTBRITE_API_KEY);
const paperCallScraperService = new PaperCallScraperService();
const playwrightPaginationScraperService = new PlaywrightPaginationScraperService();
const pretalxScraperService = new PretalxScraperService();
const pretalxScraperSimpleService = new PretalxScraperSimpleService();
const pretalxDirectService = new PretalxDirectService();

function cleanText(text) {
  if (!text) return '';
  return text
    .replace(/\n/g, ' ') 
    .replace(/\s+/g, ' ') 
    .trim(); 
}

class ScraperController {
  filterPretalxEventsByKeywords(events, input) {
    if (!input.topic && !input.industry) {
      console.log('üìä No search keywords provided, returning all events');
      return events;
    }
    
    const searchTerms = [
      input.topic?.toLowerCase(),
      input.industry?.toLowerCase()
    ].filter(Boolean);
    
    console.log('üîç Filtering events with search terms:', searchTerms);
    
    return events.filter(event => {
      const searchableText = [
        event.title?.toLowerCase() || '',
        event.description?.toLowerCase() || '',
        event.tags?.join(' ').toLowerCase() || '',
        event.organizer?.toLowerCase() || '',
        event.location?.toLowerCase() || ''
      ].join(' ');
      
      
      const matches = searchTerms.some(term => {
        if (!term) return false;
        
        
        if (searchableText.includes(term)) {
          return true;
        }
        
        
        const words = term.split(' ');
        return words.some(word => {
          if (word.length < 3) return false; 
          return searchableText.includes(word);
        });
      });
      
      if (matches) {
        console.log(`‚úÖ Event matches: "${event.title}" (matched: ${searchTerms.filter(term => searchableText.includes(term || ''))})`);
      }
      
      return matches;
    });
  }

  async scrapeEventbriteEvents(req, res) {
    try {
      const {
        maxEvents = 50,
        saveToDatabase = true,
        useApi = true,
        city = 'Los Angeles'
      } = req.body;

      console.log('Starting Eventbrite events request...');
      
      
      if (maxEvents > 200) {
        return res.status(400).json({
          success: false,
          message: 'Maximum events limit is 200'
        });
      }

      let events = [];
      let saveResult = null;

      if (useApi && process.env.EVENTBRITE_API_KEY) {
        
        console.log('Using Eventbrite API...');
        events = await apiService.searchEvents(city, {
          'page_size': parseInt(maxEvents)
        });
      } else {
        
        console.log('Using scraping approach (may be blocked)...');
        events = await scraperService.scrapeLosAngelesEvents({
          maxEvents: parseInt(maxEvents),
          headless: true,
          delay: 1000
        });
      }
      
      
      if (saveToDatabase && events.length > 0) {
        console.log('Saving events to database...');
        if (useApi && process.env.EVENTBRITE_API_KEY) {
          saveResult = await apiService.saveEventsToDatabase(events, prisma);
        } else {
          saveResult = await scraperService.saveEventsToDatabase(events, prisma);
        }
      }

      res.status(200).json({
        success: true,
        message: `Successfully fetched ${events.length} events`,
        data: {
          events: events,
          totalEvents: events.length,
          saveResult: saveResult,
          method: useApi && process.env.EVENTBRITE_API_KEY ? 'API' : 'Scraping'
        }
      });

    } catch (error) {
      console.error('Events fetch error:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to fetch events',
        error: error.message
      });
    }
  }

  async getScrapingStats(req, res) {
    try {
      
      const totalEvents = await prisma.event.count();
      
      
      const eventsBySource = await prisma.event.groupBy({
        by: ['source'],
        _count: {
          source: true
        }
      });

      
      const yesterday = new Date();
      yesterday.setDate(yesterday.getDate() - 1);
      
      const recentEvents = await prisma.event.count({
        where: {
          scrapedAt: {
            gte: yesterday
          }
        }
      });

      
      const eventsByCity = await prisma.event.groupBy({
        by: ['city'],
        _count: {
          city: true
        },
        orderBy: {
          _count: {
            city: 'desc'
          }
        }
      });

      res.status(200).json({
        success: true,
        data: {
          totalEvents,
          recentEvents,
          eventsBySource,
          eventsByCity,
          lastUpdated: new Date().toISOString()
        }
      });

    } catch (error) {
      console.error('Error getting scraping stats:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to get scraping statistics',
        error: error.message
      });
    }
  }

  async getEventDetails(req, res) {
    try {
      const { eventUrl } = req.params;

      if (!eventUrl) {
        return res.status(400).json({
          success: false,
          message: 'Event URL is required'
        });
      }

      const details = await scraperService.getEventDetails(eventUrl);

      if (!details) {
        return res.status(404).json({
          success: false,
          message: 'Event details not found'
        });
      }

      res.status(200).json({
        success: true,
        data: details
      });

    } catch (error) {
      console.error('Error getting event details:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to get event details',
        error: error.message
      });
    }
  }

  async scheduleScraping(req, res) {
    try {
      const {
        interval = 'daily', 
        maxEvents = 50,
        enabled = true
      } = req.body;

      
      
      
      res.status(200).json({
        success: true,
        message: 'Scraping schedule configured',
        data: {
          interval,
          maxEvents,
          enabled,
          nextRun: this.calculateNextRun(interval)
        }
      });

    } catch (error) {
      console.error('Error scheduling scraping:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to schedule scraping',
        error: error.message
      });
    }
  }

  calculateNextRun(interval) {
    const now = new Date();
    
    switch (interval) {
      case 'hourly':
        return new Date(now.getTime() + 60 * 60 * 1000);
      case 'daily':
        return new Date(now.getTime() + 24 * 60 * 60 * 1000);
      case 'weekly':
        return new Date(now.getTime() + 7 * 24 * 60 * 60 * 1000);
      default:
        return new Date(now.getTime() + 24 * 60 * 60 * 1000);
    }
  }

  async testScraper(req, res) {
    try {
      console.log('Testing scraper functionality...');
      
      
      const events = await scraperService.scrapeLosAngelesEvents({
        maxEvents: 5,
        headless: true,
        delay: 500
      });

      res.status(200).json({
        success: true,
        message: 'Scraper test successful',
        data: {
          eventsFound: events.length,
          sampleEvent: events[0] || null,
          testTimestamp: new Date().toISOString()
        }
      });

    } catch (error) {
      console.error('Scraper test failed:', error);
      res.status(500).json({
        success: false,
        message: 'Scraper test failed',
        error: error.message
      });
    }
  }

  async scrapePaperCallEvents(req, res) {
    try {
      const {
        maxEvents = null, 
        saveToDatabase = true,
        headless = true
      } = req.body;

      console.log('Starting PaperCall.io events request...');
      
      
      if (maxEvents && maxEvents > 1000) {
        return res.status(400).json({
          success: false,
          message: 'Maximum events limit is 1000. Set maxEvents to null to get ALL events.'
        });
      }

      let events = [];
      let saveResult = null;

      
      console.log('Using PaperCall.io scraper...');
      events = await paperCallScraperService.scrapePaperCallEvents({
        maxEvents: parseInt(maxEvents),
        headless: headless,
        delay: 1000
      });
      
      
      if (saveToDatabase && events.length > 0) {
        console.log('Saving events to database...');
        saveResult = await paperCallScraperService.saveEventsToDatabase(events, prisma);
      }
      
      const formattedEvents = events.map(event => ({
        title: cleanText(event.title) || 'No title available',
        eventUrl: event.eventUrl || 'https://www.papercall.io/pricing',
        description: cleanText(event.description) || 'No description available',
        dateTime: event.dateTime || null,
        tags: event.tags || ['Pro Event'],
        imageUrl: event.imageUrl || null,
        website: event.website || null,
        source: event.source || 'PaperCall.io',
        scrapedAt: event.scrapedAt || new Date().toISOString()
      }));

      res.status(200).json({
        success: true,
        message: `Successfully fetched ${formattedEvents.length} events from PaperCall.io`,
        data: {
          eventsFound: formattedEvents.length,
          allEvents: formattedEvents,
          saveResult: saveResult,
          method: 'PaperCall.io Scraping',
          scrapedAt: new Date().toISOString()
        }
      });

    } catch (error) {
      console.error('PaperCall.io events fetch error:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to fetch events from PaperCall.io',
        error: error.message
      });
    }
  }

  async testPaperCallScraper(req, res) {
    try {
      console.log('Testing PaperCall.io scraper functionality...');
      
      
      const events = await paperCallScraperService.scrapePaperCallEvents({
        maxEvents: 5,
        headless: true,
        delay: 500
      });

      
      const formattedEvents = events.map(event => ({
        title: cleanText(event.title) || 'No title available',
        eventUrl: event.eventUrl || 'https://www.papercall.io/pricing',
        description: cleanText(event.description) || 'No description available',
        dateTime: event.dateTime || null,
        tags: event.tags || ['Pro Event'],
        imageUrl: event.imageUrl || null,
        website: event.website || null,
        source: event.source || 'PaperCall.io',
        scrapedAt: event.scrapedAt || new Date().toISOString()
      }));

      res.status(200).json({
        success: true,
        message: 'PaperCall.io scraper test successful',
        data: {
          eventsFound: formattedEvents.length,
          allEvents: formattedEvents
        }
      });

    } catch (error) {
      console.error('PaperCall.io scraper test failed:', error);
      res.status(500).json({
        success: false,
        message: 'PaperCall.io scraper test failed',
        error: error.message
      });
    }
  }

  async scrapeWithPlaywrightPagination(req, res) {
    try {
      const {
        maxEvents = null, 
        saveToDatabase = true,
        headless = true,
        delay = 2000,
        maxPages = 50,
        scrollToLoad = true
      } = req.body;

      console.log('üöÄ Starting Playwright pagination scraper...');
      console.log(`üìä Target: ${maxEvents || 'ALL'} events, max pages: ${maxPages}`);
      
      
      if (maxEvents && maxEvents > 5000) {
        return res.status(400).json({
          success: false,
          message: 'Maximum events limit is 5000. Set maxEvents to null to get ALL events.'
        });
      }

      let events = [];
      let saveResult = null;

      
      console.log('üé≠ Using Playwright pagination scraper...');
      events = await playwrightPaginationScraperService.scrapeWithPagination({
        maxEvents: maxEvents ? parseInt(maxEvents) : null,
        headless: headless,
        delay: parseInt(delay),
        maxPages: parseInt(maxPages),
        scrollToLoad: scrollToLoad
      });
      
      
      if (saveToDatabase && events.length > 0) {
        console.log('üíæ Saving events to database...');
        saveResult = await playwrightPaginationScraperService.saveEventsToDatabase(events, prisma);
      }

      
      const formattedEvents = events.map(event => ({
        title: cleanText(event.title) || 'No title available',
        eventUrl: event.eventUrl || 'https://www.papercall.io/pricing',
        description: cleanText(event.description) || 'No description available',
        dateTime: event.dateTime || null,
        tags: event.tags || ['Pro Event'],
        imageUrl: event.imageUrl || null,
        website: event.website || null,
        source: event.source || 'PaperCall.io',
        scrapedAt: event.scrapedAt || new Date().toISOString(),
        location: event.location || null,
        eventType: event.eventType || null,
        cfpInfo: event.cfpInfo || null,
        contactEmail: event.contactEmail || null
      }));

      res.status(200).json({
        success: true,
        message: `Successfully scraped ${formattedEvents.length} events using Playwright pagination`,
        data: {
          eventsFound: formattedEvents.length,
          allEvents: formattedEvents,
          saveResult: saveResult,
          method: 'Playwright Pagination Scraping',
          scrapedAt: new Date().toISOString(),
          paginationInfo: {
            maxPages: maxPages,
            scrollToLoad: scrollToLoad,
            delay: delay
          }
        }
      });

    } catch (error) {
      console.error('‚ùå Playwright pagination scraping error:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to scrape events with Playwright pagination',
        error: error.message
      });
    }
  }

  async testPlaywrightPaginationScraper(req, res) {
    try {
      console.log('üß™ Testing Playwright pagination scraper functionality...');
      
      
      const { maxEvents = null, maxPages = 14 } = req.query;
      
      
      const events = await playwrightPaginationScraperService.scrapeWithPagination({
        maxEvents: maxEvents ? parseInt(maxEvents) : null, 
        headless: true,
        delay: 1000,
        maxPages: parseInt(maxPages),
        scrollToLoad: true
      });

      
      const formattedEvents = events.map(event => ({
        title: cleanText(event.title) || 'No title available',
        eventUrl: event.eventUrl || 'https://www.papercall.io/pricing',
        description: cleanText(event.description) || 'No description available',
        dateTime: event.dateTime || null,
        tags: event.tags || ['Pro Event'],
        imageUrl: event.imageUrl || null,
        website: event.website || null,
        source: event.source || 'PaperCall.io',
        scrapedAt: event.scrapedAt || new Date().toISOString(),
        location: event.location || null,
        eventType: event.eventType || null,
        cfpInfo: event.cfpInfo || null,
        contactEmail: event.contactEmail || null
      }));

      res.status(200).json({
        success: true,
        message: 'Playwright pagination scraper test successful',
        data: {
          eventsFound: formattedEvents.length,
          allEvents: formattedEvents,
          testTimestamp: new Date().toISOString(),
          testConfig: {
            maxEvents: maxEvents || 'ALL',
            maxPages: parseInt(maxPages),
            scrollToLoad: true
          }
        }
      });

    } catch (error) {
      console.error('‚ùå Playwright pagination scraper test failed:', error);
      res.status(500).json({
        success: false,
        message: 'Playwright pagination scraper test failed',
        error: error.message
      });
    }
  }

  async getAllPaperCallEvents(req, res) {
    try {
      console.log('üöÄ Getting ALL PaperCall.io events (no limits)...');
      
      
      const events = await playwrightPaginationScraperService.scrapeWithPagination({
        maxEvents: null,        
        headless: true,
        delay: 2000,           
        maxPages: 14,          
        scrollToLoad: true
      });

      
      const formattedEvents = events.map(event => ({
        title: cleanText(event.title) || 'No title available',
        eventUrl: event.eventUrl || 'https://www.papercall.io/pricing',
        description: cleanText(event.description) || 'No description available',
        dateTime: event.dateTime || null,
        tags: event.tags || ['Pro Event'],
        imageUrl: event.imageUrl || null,
        website: event.website || null,
        source: event.source || 'PaperCall.io',
        scrapedAt: event.scrapedAt || new Date().toISOString(),
        location: event.location || null,
        eventType: event.eventType || null,
        cfpInfo: event.cfpInfo || null,
        contactEmail: event.contactEmail || null
      }));

      res.status(200).json({
        success: true,
        message: `Successfully scraped ALL ${formattedEvents.length} events from PaperCall.io`,
        data: {
          eventsFound: formattedEvents.length,
          allEvents: formattedEvents,
          method: 'Playwright Pagination Scraping - ALL EVENTS',
          scrapedAt: new Date().toISOString(),
          paginationInfo: {
            totalPages: 14,
            eventsPerPage: Math.ceil(formattedEvents.length / 14),
            scrollToLoad: true,
            delay: 2000
          }
        }
      });

    } catch (error) {
      console.error('‚ùå Error getting all PaperCall.io events:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to get all PaperCall.io events',
        error: error.message
      });
    }
  }

  async scrapeAndSaveAllEvents(req, res) {
    try {
      const events = await playwrightPaginationScraperService.scrapeWithPagination({
        maxEvents: null,        
        headless: true,
        delay: 2000,           
        maxPages: 14,          
        scrollToLoad: true
      });

      const saveResult = await playwrightPaginationScraperService.saveEventsToDatabase(events, prisma);
      
      const formattedEvents = events.map(event => ({
        title: cleanText(event.title) || 'No title available',
        eventUrl: event.eventUrl || 'https://www.papercall.io/pricing',
        description: cleanText(event.description) || 'No description available',
        dateTime: event.dateTime || null,
        tags: event.tags || ['Pro Event'],
        imageUrl: event.imageUrl || null,
        website: event.website || null,
        source: event.source || 'PaperCall.io',
        scrapedAt: event.scrapedAt || new Date().toISOString(),
        location: event.location || null,
        eventType: event.eventType || null,
        cfpInfo: event.cfpInfo || null,
        contactEmail: event.contactEmail || null
      }));

      res.status(200).json({
        success: true,
        message: `Successfully scraped and saved ${saveResult.saved} events to database`,
        data: {
          eventsScraped: events.length,
          eventsSaved: saveResult.saved,
          eventsSkipped: saveResult.errors,
          allEvents: formattedEvents,
          saveResult: saveResult,
          method: 'Playwright Pagination Scraping + Database Save',
          scrapedAt: new Date().toISOString(),
          paginationInfo: {
            totalPages: 14,
            eventsPerPage: Math.ceil(events.length / 14),
            scrollToLoad: true,
            delay: 2000
          }
        }
      });

    } catch (error) {
      console.error('‚ùå Error scraping and saving events:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to scrape and save events to database',
        error: error.message
      });
    }
  }

  async cleanupOldEvents(req, res) {
    try {
      const { daysOld = 30 } = req.body;
      
      const cutoffDate = new Date();
      cutoffDate.setDate(cutoffDate.getDate() - parseInt(daysOld));

      const deletedEvents = await prisma.event.deleteMany({
        where: {
          scrapedAt: {
            lt: cutoffDate
          }
        }
      });

      res.status(200).json({
        success: true,
        message: `Cleaned up ${deletedEvents.count} old events`,
        data: {
          deletedCount: deletedEvents.count,
          cutoffDate: cutoffDate.toISOString()
        }
      });

    } catch (error) {
      console.error('Error cleaning up old events:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to clean up old events',
        error: error.message
      });
    }
  }


  async scrapePretalxEvents(req, res) {
    try {
      const {
        maxEvents = null, 
        saveToDatabase = true,
        headless = true,
        delay = 1000,
        includePageDetails = false,
        
        topic = null,
        industry = null
      } = req.body;

      console.log('üöÄ Starting Pretalx events scraping...');
      
      
      if (maxEvents && maxEvents > 1000) {
        return res.status(400).json({
          success: false,
          message: 'Maximum events limit is 1000. Set maxEvents to null to get ALL events.'
        });
      }

      let result = null;
      let saveResult = null;

      
      console.log('üéØ Using direct Pretalx service for automatic event collection...');
      result = await pretalxDirectService.getEventsForSearch({
        maxEvents: maxEvents ? parseInt(maxEvents) : 30,
        maxConcurrent: 3,
        delay: parseInt(delay) || 300
      });
      
      
      if (!result || !result.events) {
        console.error('‚ùå Invalid result structure from Pretalx service:', result);
        return res.status(500).json({
          success: false,
          message: 'Failed to get events from Pretalx service',
          error: 'Invalid result structure'
        });
      }
      
      
      if (saveToDatabase && result.events.length > 0) {
        console.log('üíæ Saving events to database...');
        saveResult = await pretalxScraperService.saveEventsToDatabase(result.events, prisma);
      }

      
      let filteredEvents = result.events;
      if (topic || industry) {
        console.log(`üéØ Filtering events by keywords: topic="${topic}", industry="${industry}"`);
        filteredEvents = this.filterPretalxEventsByKeywords(result.events, { topic, industry });
        console.log(`üìä Filtered from ${result.events.length} to ${filteredEvents.length} events`);
      }

      
      const formattedEvents = filteredEvents.map(event => ({
        slug: event.slug || event.id,
        title: event.title || event.pageDetails?.title || event.slug || event.id,
        eventUrl: event.eventUrl,
        description: event.description || event.pageDetails?.description || `Pretalx event: ${event.slug || event.id}`,
        dateTime: event.dateTime || event.pageDetails?.date,
        location: event.location || event.pageDetails?.location,
        organizer: event.organizer || event.pageDetails?.organizer,
        website: event.website || event.pageDetails?.website,
        contactEmail: event.contactEmail || event.pageDetails?.contactEmail,
        tags: event.tags || event.pageDetails?.tags || [],
        cfpDeadline: event.cfpDeadline || event.pageDetails?.cfpDeadline,
        eventType: event.eventType || event.pageDetails?.eventType || 'Conference',
        totalTalks: event.totalTalks,
        talks: event.talks,
        source: 'Pretalx',
        scrapedAt: event.scrapedAt,
        
        eventStartDate: event.eventStartDate,
        eventEndDate: event.eventEndDate,
        id: event.id || event.slug
      }));

      res.status(200).json({
        success: true,
        message: `Successfully scraped ${formattedEvents.length} events from Pretalx`,
        data: {
          eventsFound: formattedEvents.length,
          allEvents: formattedEvents,
          saveResult: saveResult,
          method: 'Pretalx Scraping',
          scrapedAt: new Date().toISOString(),
          summary: result.summary,
          errors: result.errors
        }
      });

    } catch (error) {
      console.error('‚ùå Pretalx events scraping error:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to scrape events from Pretalx',
        error: error.message
      });
    }
  }

  async testPretalxScraper(req, res) {
    try {
      console.log('üß™ Testing Pretalx scraper functionality...');
      
      let result;
      let useFallback = false;
      
      try {
        
        result = await pretalxDirectService.getEventsForSearch({
          maxEvents: 15,
          maxConcurrent: 3,
          delay: 300
        });
        
        
        if (!result.success || result.events.length === 0) {
          console.log('‚ö†Ô∏è No events found, using fallback data...');
          useFallback = true;
        }
      } catch (scraperError) {
        console.error('‚ùå Direct service failed, using fallback data:', scraperError.message);
        useFallback = true;
      }
      
      if (useFallback) {
        
        result = {
          events: [
            {
              slug: 'pycon-2025',
              eventUrl: 'https://pretalx.com/pycon-2025/',
              totalTalks: 45,
              talks: [],
              pageDetails: null,
              source: 'Pretalx',
              scrapedAt: new Date().toISOString()
            },
            {
              slug: 'jsconf-2025',
              eventUrl: 'https://pretalx.com/jsconf-2025/',
              totalTalks: 32,
              talks: [],
              pageDetails: null,
              source: 'Pretalx',
              scrapedAt: new Date().toISOString()
            },
            {
              slug: 'devops-con-2025',
              eventUrl: 'https://pretalx.com/devops-con-2025/',
              totalTalks: 28,
              talks: [],
              pageDetails: null,
              source: 'Pretalx',
              scrapedAt: new Date().toISOString()
            }
          ],
          errors: [],
          summary: {
            totalSlugs: 3,
            successfulEvents: 3,
            failedEvents: 0,
            totalTalks: 105
          }
        };
      }

      
      const formattedEvents = result.events.map(event => ({
        slug: event.slug || event.id,
        title: event.title || event.pageDetails?.title || event.slug || event.id,
        eventUrl: event.eventUrl,
        description: event.description || event.pageDetails?.description || `Pretalx event: ${event.slug || event.id}`,
        dateTime: event.dateTime || event.pageDetails?.date,
        location: event.location || event.pageDetails?.location,
        organizer: event.organizer || event.pageDetails?.organizer,
        website: event.website || event.pageDetails?.website,
        contactEmail: event.contactEmail || event.pageDetails?.contactEmail,
        tags: event.tags || event.pageDetails?.tags || [],
        cfpDeadline: event.cfpDeadline || event.pageDetails?.cfpDeadline,
        eventType: event.eventType || event.pageDetails?.eventType || 'Conference',
        totalTalks: event.totalTalks,
        talks: event.talks,
        source: 'Pretalx',
        scrapedAt: event.scrapedAt,
        
        eventStartDate: event.eventStartDate,
        eventEndDate: event.eventEndDate,
        id: event.id || event.slug
      }));

      res.status(200).json({
        success: true,
        message: useFallback ? 'Pretalx scraper test successful (using fallback data)' : 'Pretalx scraper test successful',
        data: {
          eventsFound: formattedEvents.length,
          allEvents: formattedEvents,
          summary: result.summary,
          errors: result.errors,
          testTimestamp: new Date().toISOString(),
          usedFallback: useFallback
        }
      });

    } catch (error) {
      console.error('‚ùå Pretalx scraper test failed:', error);
      res.status(500).json({
        success: false,
        message: 'Pretalx scraper test failed',
        error: error.message
      });
    }
  }

  async getAllPretalxEventIds(req, res) {
    try {
      const { maxEvents = null } = req.body;

      console.log('üîç Getting all Pretalx event IDs automatically...');
      
      const eventIds = await pretalxDirectService.getAllEventIds({
        maxEvents
      });

      res.status(200).json({
        success: true,
        message: 'Event IDs retrieved successfully',
        data: {
          eventIds: eventIds,
          totalIds: eventIds.length
        }
      });

    } catch (error) {
      console.error('‚ùå Error getting event IDs:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to get event IDs',
        error: error.message
      });
    }
  }

  async getPretalxEventSlugs(req, res) {
    try {
      const {
        maxEvents = null,
        headless = true,
        delay = 1000
      } = req.body;

      console.log('üìã Getting Pretalx event slugs...');
      
      const eventSlugs = await pretalxScraperService.getEventSlugs({
        maxEvents: maxEvents ? parseInt(maxEvents) : null,
        headless: headless,
        delay: parseInt(delay)
      });

      res.status(200).json({
        success: true,
        message: `Successfully extracted ${eventSlugs.length} event slugs`,
        data: {
          eventSlugs: eventSlugs,
          totalSlugs: eventSlugs.length,
          scrapedAt: new Date().toISOString()
        }
      });

    } catch (error) {
      console.error('‚ùå Error getting Pretalx event slugs:', error);
      res.status(500).json({
        success: false,
        message: 'Failed to get Pretalx event slugs',
        error: error.message
      });
    }
  }


  async getPretalxEventDetails(req, res) {
    try {
      const { slug } = req.params;
      const { includePageDetails = false } = req.query;

      if (!slug) {
        return res.status(400).json({
          success: false,
          message: 'Event slug is required'
        });
      }

      console.log(`üìä Getting Pretalx event details for slug: ${slug}`);
      
      
      const apiDetails = await pretalxScraperService.getEventDetails(slug);
      
      
      let pageDetails = null;
      if (includePageDetails === 'true') {
        pageDetails = await pretalxScraperService.getEventPageDetails(slug);
      }

      const event = {
        ...apiDetails,
        pageDetails: pageDetails,
        source: 'Pretalx',
        scrapedAt: new Date().toISOString()
      };

      res.status(200).json({
        success: true,
        message: `Successfully fetched event details for ${slug}`,
        data: {
          event: event,
          scrapedAt: new Date().toISOString()
        }
      });

    } catch (error) {
      console.error(`‚ùå Error getting Pretalx event details for ${req.params.slug}:`, error);
      res.status(500).json({
        success: false,
        message: 'Failed to get Pretalx event details',
        error: error.message
      });
    }
  }
}

module.exports = new ScraperController();
